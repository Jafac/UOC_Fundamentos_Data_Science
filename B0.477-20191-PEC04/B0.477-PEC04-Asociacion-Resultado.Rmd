---
title: 'Reglas de Asociación'
author: "Autor: Albert Campano"
date: "Enero 2020"
output:
  html_document:
    fig_height: 5
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_depth: 2
    includes:
      in_header: B0.477-PEC-header.html    
  pdf_document:
    toc: yes
  word_document: default
editor_options: 
  chunk_output_type: console
---
******
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******
## Descripción de la PEC a realizar
La prueba está estructurada en un total de 5 ejercicios prácticos. Es necesario hacerlos todos para obtener una valoración máxima.

## Criterios de valoración
Pregunta  | Criterio de valoración        | Peso
----- | ---------------------------------- | ------
1  | Se explican los distintos métodos que acepta la función | 10%
1  | Se aplican los métodos y se muestran los resultados | 10%
2  | Se listan las 10 reglas solicitadas  | 5%
2  | Se genera y se comenta el gráfico solicitado  | 5%
2  | Se comentan 2 reglas de las 10 generadas  | 10%
3  | Se explica para que sirve la función coverage()  | 5%
3  | Se listan las 10 reglas solicitadas  | 5%
3  | Se genera y se comenta el gráfico solicitado  | 10%
4  | Se generan y se muestran los sets solicitados  | 5%
4  | Se listan las 10 reglas solicitadas  | 10%
5  | Se explica el significado de los 3 conceptos solicitados  | 5%
5  | Se explica una regla detallando el significado en la regla del soporte, confianza y elevación  | 10%
6  | Se plasma a través de una redacción extensa el conocimiento obtenido a partir de las reglas generadas  | 10%

## Formato y fecha de entega
El formato de entrega es: studentname-PECn.html  
Fecha de Entrega: 02/02/2020  
Se debe entregar la PEC en el buzón de entregas del aula  

******
# Información técnica de la PEC
******
A continuación se ofrece información técnica sobre el entorno en el que se ha generado este documento
```{r,eval=TRUE,echo=TRUE}
# Encoding utilizado: UTF-8

# Datos de sistema operativo y versión R
version

# Versión de los paquetes utilizados:
# Paquete arules
packageVersion("arules")

# Paquete arulesViz
packageVersion("arulesViz")
```

******
# Base teórica
******
Para realizar la práctica se recomienda la lectura del punto 3.4 del material didáctico. Este punto se centra en la búsqueda de asociaciones las cuales en nuestro caso se darán entre las características de la población adulta de USA.

El algoritmo **apriori** fue diseñado para la búsqueda de asociaciones entre los productos que forman parte de la cesta de la compra en el supermercado, hipermercado o gran superficie. El objetivo era determinar qué productos eran causa de la compra de otros. Sin embargo, el algoritmo **apriori** puede generalizarse para la búsqueda de asociaciones entre cualquier conjunto de items.  

En esta PEC el objetivo será buscar asociaciones y relaciones en un juego de datos sobre la población adulta de USA. Se han identificado una serie de características de la misma y se quiere averiguar si existen relaciones entre ellas.

Para ello utilizaremos el paquete **R** denominado **arules** del que podréis encontrar información extensa en el siguiente enlace https://cran.r-project.org/web/packages/arules/vignettes/arules.pdf  

******
# Descripción del problema
******
Vamos a analizar la relación entre características que definen la población adulta de USA según las siguientes variables.  

01. age
02. workclass  
03. fnlwgt: final weight
04. education
05. education-num
06. marital-status
07. occuptaion
08. relationship  
09. race  
10. sex  
11. capital-gain
12. capital-loss
13. hours-per-week  
14. native-country  
15. income

Podéis encontrar más información sobre el juego de datos en el siguiente enlace https://archive.ics.uci.edu/ml/datasets/adult

******
# Cargar el juego de datos
******
El juego de datos forma parte de los ejemplos del paquete **arules**, por lo que una vez cargado el paquete simplemente tendremos que llamarlo. Para poder ser usado por algoritmos de búsqueda de asociaciones el juego de datos debe tener una estructura de transacciones en la que cada fila represente una transacción, por ejemplo en una cesta de la compra diríamos que cada fila representa una compra.  

En nuestro caso una transacción o fila del juego de datos representa un individuo de la población de USA.  

La generación de reglas de asociación requiere que las características a estudiar sean categóricas y no continuas, por este motivo debemos prever un proceso de conversión de variables continuas en categóricas, para ello nos apoyaremos en la función de **R** **cut()**.  


```{r,eval=TRUE,echo=TRUE}
library(arules)
library(arulesViz)
data("AdultUCI")

# Proceso de categorización de variables continuas
AdultC <- AdultUCI
AdultC$age <- cut(AdultUCI$age, c(15,25,30,35,45,55,65,100))
AdultC$workclass <- AdultUCI$workclass
AdultC$fnlwgt <- cut(AdultUCI$fnlwgt, c(12200,20000,50000,100000,500000,750000,1000000,1500000))
AdultC$education <- AdultUCI$education
AdultC$`education-num` <- cut(AdultUCI$`education-num`, c(1,5,10,15,20))
AdultC$`marital-status` <- AdultUCI$`marital-status`
AdultC$occupation <- AdultUCI$occupation
AdultC$relationship <- AdultUCI$relationship
AdultC$race <- AdultUCI$race
AdultC$sex <- AdultUCI$sex
AdultC$`capital-gain` <- cut(AdultUCI$`capital-gain`, c(0,15000,20000,30000,40000,50000,60000,80000,100000))
AdultC$`capital-loss` <- cut(AdultUCI$`capital-loss`, c(0,500,1000,2000,3000,4000,5000))
AdultC$`hours-per-week` <- cut(AdultUCI$`hours-per-week`, c(0,10,20,30,50,60,80,100))
AdultC$`native-country` <- AdultUCI$`native-country`
AdultC$income <- AdultUCI$income
```


******
# Función arules()
******

En R el juego de datos debe estar en formato **transaction**. Si no lo está, deberemos usar comandos de **R** para proceder a su conversión.  
Observamos que en el proceso de generación de reglas exigimos un soporte y una confianza mínimos.  

```{r,eval=TRUE,echo=TRUE}
# Conversión del juego de datos a formato transacción
Adult = as(AdultC, "transactions")

# Visualizamos un histograma de frecuencias
itemFrequencyPlot(Adult,topN=20,type="absolute")

# Generación de reglas con soporte y confianza mínimos
rules = apriori(Adult, parameter=list(support=0.01, confidence=0.7, maxlen=7))

# Listado de reglas obtenidas 
rules
```


Vemos como el número de reglas que se han formado superan las 170000, por ello es importante poder filtrar entre las reglas generadas, siendo tarea del analista identificar las más representativas. Mostramos a continuación formas distintas de filtrado de reglas.  

```{r,eval=TRUE,echo=TRUE}
# Listamos las 3 reglas con mayor lift
inspect(head(sort(rules, by="lift"),3));

# Visualizamos la calidad de las reglas generadas 
head(quality(rules));

# Generamos gráfico de frecuencias por elevación
plot(quality(rules)$lift,quality(rules)$count)
```


Más técnicas de filtrado de reglas  

```{r,eval=TRUE,echo=TRUE}
# Extracción de reglas con una confianza superior a 0.8
subrules = rules[quality(rules)$confidence > 0.8]
 
subrules
```

Filtramos las 20 reglas con mayor elevación y posteriormente las listamos

```{r,eval=TRUE,echo=TRUE}
subrules2 = head(sort(rules, by="lift"), 20);
 
subrules2
inspect(subrules2)

oneRule = sample(rules, 1);
 
inspect(oneRule);
```


******
# Visualizaciones de reglas
******
La forma más habitual de trabajar con reglas es listarlas en forma de tabla, que es lo que hemos hecho hasta ahora. 
```{r,eval=TRUE,echo=TRUE}
inspectRules <- inspect(rules[1:10], ruleSep = "---->", itemSep = " + ", setStart = "", setEnd ="", linebreak = FALSE)
knitr::kable(inspectRules)
```

Sin embargo, existen técnicas más gráficas como los árboles de reglas.
```{r,eval=TRUE,echo=TRUE}
library(arulesViz)
# Gráfico basado en árboles de reglas
plot(rules[1:10], method="graph")

# Gráfico de puntos
plot(rules[1:50], measure=c("support", "confidence"), shading="lift")

plot(rules[1:50], shading="order", control=list(main = "Two-key plot"))

# Comparando rhs con lhs
plot(rules[1:50], method="matrix", measure="lift")
```


******
# Función eclat()
******

Una aproximación distinta puede ser usar la función **R** **eclat()** para identificar los valores más significativos de las distintas características

```{r,eval=TRUE,echo=TRUE}
itemFrequencyPlot(Adult, support = 0.1, cex.names=0.8)
 
# Creamos sets o combinaciones de características según su relevancia.
fsets = eclat(Adult, parameter = list(support = 0.05), control = list(verbose=FALSE));
summary(fsets)
# Seleccionamos los sets con un solo item o característica
singleItems = fsets[size(items(fsets)) == 1];
inspect(singleItems)

singleSupport = quality(singleItems)$support;
 
names(singleSupport) = unlist(LIST(items(singleItems), decode = FALSE));
 
head(singleSupport, n = 5);
 

itemsetList = LIST(items(fsets), decode = FALSE);
 
# Determinamos la confianza de cada set
allConfidence = quality(fsets)$support / sapply(itemsetList, function(x) max(singleSupport[as.character(x)]));
 
quality(fsets) = cbind(quality(fsets), allConfidence);
 
summary(fsets)

```


******
# Preguntas
******

******
## Pregunta 1
******
Al inicio de la práctica se realiza una tarea de categorización o discretización de las variables continuas del juego de datos AdultUCI.  

El paquete **arules** dispone de la función **discretize()** para proceder a realizar tareas de categorización de variables contínuas.  

Explica qué métodos de discretización acepta esta variable y aplica cada método en la tabla AdultUCI para categorizar sus variables continuas.  

**Atención!** El método "frequency" puede dar el siguiente error "Some breaks are not unique, use fewer breaks for the data".
Es normal, simplemente reducid el númeo de intervalos.

**Respuesta**
Los métodos que existen son:
- Frequency: Se generan los intervalos de forma que tengan la misma frecuencia
- Interval: Los intervalos siempre tienen la misma distancia entre ellos
- Cluster: Usa k-means para hacer grupos que seran los intervalos
- Fixed: Nosotros fijamos los intervalos (equivalente a lo que se habia hecho anteriormente)

Usaremos la función **discretize()** con diferentes metodos en cada una de las variables.
```{r,eval=TRUE,echo=TRUE}
# Proceso de categorización de variables continuas
AdultC2 <- AdultUCI

#AdultCX$age <- cut(AdultUCI$age, c(15,25,30,35,45,55,65,100))
AdultC2$age <- discretize(AdultUCI$age, method = "cluster", breaks = 7)
AdultC2$workclass <- AdultUCI$workclass
#AdultC2$fnlwgt <- cut(AdultUCI$fnlwgt, c(12200,20000,50000,100000,500000,750000,1000000,1500000))
AdultC2$fnlwgt <- discretize(AdultUCI$fnlwgt, method = "frequency", breaks = 7)
AdultC2$education <- AdultUCI$education
#AdultC2$`education-num` <- cut(AdultUCI$`education-num`, c(1,5,10,15,20))
AdultC2$`education-num` <- discretize(AdultUCI$`education-num`, method = "fixed", breaks = c(1,5,10,15,20))
AdultC2$`marital-status` <- AdultUCI$`marital-status`
AdultC2$occupation <- AdultUCI$occupation
AdultC2$relationship <- AdultUCI$relationship
AdultC2$race <- AdultUCI$race
AdultC2$sex <- AdultUCI$sex
#AdultC2$`capital-gain` <- cut(AdultUCI$`capital-gain`, c(0,15000,20000,30000,40000,50000,60000,80000,100000))
AdultC2$`capital-gain` <- discretize(AdultUCI$`capital-gain`, method = "interval", breaks = 8)
#AdultC2$`capital-loss` <- cut(AdultUCI$`capital-loss`, c(0,500,1000,2000,3000,4000,5000))
AdultC2$`capital-loss` <- discretize(AdultUCI$`capital-loss`, method = "interval", breaks = 6)
#AdultC2$`hours-per-week` <- cut(AdultUCI$`hours-per-week`, c(0,10,20,30,50,60,80,100))
AdultC2$`hours-per-week` <- discretize(AdultUCI$`hours-per-week`, method = "fixed", breaks = c(0,10,20,30,50,60,80,100))
AdultC2$`native-country` <- AdultUCI$`native-country`
AdultC2$income <- AdultUCI$income
```


******
## Pregunta 2
******
1. Lista las 10 reglas del conjunto **rules** con más soporte.
2. Genera un gráfico de frecuencias por soporte para las 100 primeras reglas con más soporte.
3. Comenta 2 reglas

**Respuesta**
```{r}
# Listamos las 10 reglas con mayor soporte
inspect(head(sort(rules, by="support"),10));

first.100.rules <- head(sort(rules, by="support"),100)
plot(quality(first.100.rules)$support,quality(first.100.rules)$count)

inspect(head(first.100.rules))
```

En el grafico podemos ver una relación directa entre el soporte y la frecuencia. Eso es debido a que el soporte es el porcentaje de transacciones que contienen union('lhs','rhs')

Vamos a comentar esta dos reglas:
hs                               rhs
{}                             => {native-country=United-States}
{race=White}                   => {native-country=United-States}

En la primera regla se dice que todos los habitantes son nativos de Estados Unidos (cuando 'lhs' es vacio implica que 'rhs' siempre es cierto)
En la segunda regla se dice que si un habitante es de 'raza' blanca, entonces es nativo de Estados Unidos.



******
## Pregunta 3
******
1. Investigad el funcionamiento de la función **coverage()** y aplicadlo a la variable **rules**.
2. Lista las 10 reglas con **coverage** más alto.
3. Genera un gráfico de frecuencias por **coverage**.

**Respuesta**
Usando la función **help()** para ver la función **coverage()** podemos saber que esta calcula la cobertura (soporte de la parte derecha) de las reglas.

```{r}
#Añadimos una columna coverage
rules.with.coverage <- rules
quality(rules.with.coverage) <- cbind(quality(rules.with.coverage), coverage = coverage(rules.with.coverage))

# Listamos las 10 reglas con mayor soporte
inspect(head(sort(rules.with.coverage, by="coverage"),10));

plot(quality(rules.with.coverage)$coverage,quality(rules.with.coverage)$count)
```

Dado que la cobertura tambien es un calculo de soporte, deberia seguir una relación similar a la que hemos podido comprobar en la grafica del ejercicio anterior. Exactamente, esta grafica tiene una relación directa entre la cobertura y la frecuencia.

******
## Pregunta 4
******
1. A partir del conjunto de reglas fsets generado con la función **eclat()** en el enunciado de la PEC, genera sets (conjuntos) de 2 items o caraterísticas.
2. A partir del set de 2 items generado, lista las 5 reglas con mayor soporte.

**Respuesta**
```{r}
two.Items = fsets[size(items(fsets)) == 2];
inspect(two.Items)

inspect(head(sort(two.Items, by="support"),10));
```

******
## Pregunta 5
******
Escoje una de las reglas generadas y comenta los valores de soporte, confianza y elevación que tiene asociados.  
1.  ¿Qué significa cada uno de los 3 conceptos?   
2.  Aplica cada una de las 3 definiciones a la regla seleccionada   

**Respuesta**
-**Soporte:** Es un indicador de tan frecuente es un itemset en el conjunto de datos.
-**Confianza:** Es un indicador del grado de fiabilidad de una regla. 
-**Elevación:** Ratio del soporte observado contra el esperado si 'lhs' y 'rhs' fuesen independientes. Cuando elevación = 1 (independientes entre sí), no se puede establecer ninguna regla. Mayores valores de elevación indican
asociaciones más fuertes.

Usaremos esta regla:
lhs                               rhs                            support   confidence lift      count
{race=White}                   => {native-country=United-States} 0.7881127 0.9217231  1.0270761 38493

El soporte de 0.788 indica que el 78.8% de las habitantes son de 'raza' blanca.
La confianza de 0.921 indicia que de todos los habitantes de 'raza' blanca, el 92.1% son nativos de Estados Unidos.
El lift es 1.027 (superior a 1), por tanto, es una regla valida (no lo podemos asegurar con rotundidad dado que el lift solo es ligeramente superior a 1, una buena idea seria hacer un test de Fisher)


******
## Pregunta 6
******
El objetivo de todo estudio analítico es la extracción de conocimiento o inteligencia, **insight** en inglés.  
Explicad en este apartado qué conocimiento se puede extraer de nuestro juego de datos a partir de las reglas generadas.

**Respuesta**
Muchas de las reglas, tenian un lift igual (o similar) a uno. Cuando esto pasa las variables son independientes y por tanto, no es posible extraer información de esa regla.

Lo que podemos hacer es calcular si una regla es significativa mediante el test de Fisher. 
La función **is.significant()** nos indica si una regla es significante comparando el p-value del test de Fisher con el alpha que nosotros decidamos (en este caso 0.05).

Haremos un analisis con las siguientes reglas:
- Soporte de mas del 60%
- Confianza de mas del 80%
- Lift superior a 1
- Reglas que sean significantes

```{r}
metricas <- interestMeasure(rules, measure = c("support", "confidence","lift", "fishersExactTest"), transactions = Adult)
rules.significant <- is.significant(rules, Adult, method = "fisher", alpha = 0.05)
quality(rules) <- cbind(metricas, significant = rules.significant)
subrules.significant <- rules[quality(rules)$support > 0.6 & quality(rules)$confidence > 0.8 & quality(rules)$lift > 1.0 & quality(rules)$significant == TRUE];
inspect(head(sort(subrules.significant,by="confidence"), 10))
```

Comentaremos estas reglas que nos han aparecido:
- La gente de 'raza' blanca son nativos de Estados Unidos y viceversa( reglas 1 y 4).
- Reglas similares nos aparecen (reglas 2 y 3). Podriamos descartar estas 2 debido a que las anteriores son mas genericas

Si modificamos el soporte y la confianza podemos encontrar otras reglas:
```{r}
subrules.significant <- rules[quality(rules)$support > 0.1 & quality(rules)$confidence > 0.95 & quality(rules)$lift > 1.0 & quality(rules)$significant == TRUE];
inspect(head(sort(subrules.significant,by="lift"), 5))
```
En general, en estas reglas encontramos que la gente con educación universitaria (Bachelors) ha estudiado entre 10 y 15 años.
Atención: cuanto mas bajo sea el soporte apareceran reglas que se den menos en nuestro set de datos, si bajamos demasiado este numero apareceran reglas que no se suelen dar en la vida real. El soporte minimo aceptable variara en función del tamaño de los datos de entrada.

Asi pues, modificanco las variables de soporte, confianza i lift podemos encontrar reglas que nos permitan extraer conocimiento de este set de datos. Incluso pueden ayudarnos a hacer predicciones futuras.